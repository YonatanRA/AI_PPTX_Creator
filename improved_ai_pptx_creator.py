# Standard library imports
import os
import sys

# Third-party imports
from dotenv import load_dotenv
from langchain_openai.chat_models import ChatOpenAI
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
from langchain.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import OpenAI

# Load environment variables
load_dotenv()

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    raise ValueError("OPENAI_API_KEY not found in environment variables. Please check your .env file.")
else:
    print("API Key loaded successfully.")


from langchain_openai.chat_models import ChatOpenAI   # LangChain connection to OpenAI

model = ChatOpenAI(model="gpt-4-turbo")

response = model.invoke("What is the Suez Canal?")

response.content

os.listdir("../pdfs")

from langchain_community.document_loaders import PyPDFDirectoryLoader

# loading pdf file

loader = PyPDFDirectoryLoader("../pdfs/")

pages = loader.load()

# nÂº of pages in pdf

len(pages)

# embedding model from OpenAI

from langchain_openai.embeddings import OpenAIEmbeddings

vectorizer = OpenAIEmbeddings()

# storing vectors in ChromaDB

from langchain_community.vectorstores import Chroma

chroma_db = Chroma.from_documents(pages, vectorizer, persist_directory="../chroma_db")

# object to retrieve 2 pages with maximal marginal relevance algorithm

retriever = chroma_db.as_retriever(search_type="mmr", search_kwargs={"k": 2, "lambda_mult": 0.25})

from langchain.prompts import ChatPromptTemplate

template = """
            Given the context below and the question, 
            please generate a header and 10 bullet points.
            List with numbers the bullet points.
            Summarize each bullet point in 40 words.
            
            Put a line separator after `:` symbol.

            Context: {context}

            Question: {question}
            """


prompt = ChatPromptTemplate.from_template(template)

from langchain_core.output_parsers import StrOutputParser

parser = StrOutputParser()

from langchain_core.runnables import RunnablePassthrough

query = "What are the endnotes of the briefing?"

in_chain = {"context": retriever, "question": RunnablePassthrough()} | prompt | model | parser


response = in_chain.invoke(query)

response.split("\n")

from langchain_openai import OpenAI

input_model = OpenAI(temperature=0, max_tokens=1024)

template = """
            You are an expert Python developer proficient in the python-pptx library.
            
            Task: Generate a complete, executable Python script using python-pptx to create a presentation based on the information provided below.
            
            Specifications:
            1.  **Output File**: Save the presentation to "../pptx/Red Sea Security Threats.pptx".
            2.  **Structure**:
                *   **Slide 1 (Title Slide)**: Use layout 0. Title: "Endnotes of the March 2024 EPRS Briefing". Subtitle: "Generated by AI".
                *   **Slide 2 (Content)**: Use layout 1. Title: "Key Insights (Part 1)". Content: First 5 bullet points from the information.
                *   **Slide 3 (Content)**: Use layout 1. Title: "Key Insights (Part 2)". Content: Remaining 5 bullet points from the information.
            3.  **Formatting**:
                *   Use a clear font size (e.g., 20pt) for the body text.
                *   Ensure text does not overlap or overflow.
            4.  **Code Quality**:
                *   Include all necessary imports ("from pptx import Presentation", "from pptx.util import Pt", etc.).
                *   Ensure the code is self-contained and ready to run.
                *   Do NOT include any markdown formatting (like ```python) in your output, just the raw code.

            Information:
            {context}
            """

prompt = ChatPromptTemplate.from_template(template)


out_chain = prompt | input_model | parser

output = out_chain.invoke({"context": response})

output.split("\n")

# example

exec("print(2+2)")

def clean_python_code(code_str):
    """Removes markdown code block syntax from a string."""
    if '```python' in code_str:
        code_str = code_str.split('```python')[1]
    if '```' in code_str:
        code_str = code_str.split('```')[0]
    return code_str.strip()


# Clean and execute the generated code
cleaned_code = clean_python_code(output)
print("Executing the following code:\n", cleaned_code)
try:
    exec(cleaned_code)
    print("Presentation created successfully!")
except Exception as e:
    print(f"Error executing code: {e}")




